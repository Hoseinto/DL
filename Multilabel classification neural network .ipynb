{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2349ba5",
   "metadata": {},
   "source": [
    "# Multi-label classification neural network on COVID data\n",
    "\n",
    "The main goal of this code is to develope a prediction model for prognosis of COVID-19 patients based on classification approach with multiple outcomes\n",
    "\n",
    "Moreover, specific goals of this code includes:\n",
    "\n",
    "- Developing a prediction model for the prognosis of COVID-19 patients based on classification approach to predict mortality\n",
    "- Developing a prediction model for the prognosis of COVID-19 patients based on classification approach to predict ICU admission\n",
    "- Developing a prediction model for the prognosis of COVID-19 patients based on classification approach to predict intubation\n",
    "- Developing a prediction model for the prognosis of COVID-19 patients based on classification approach to predict dialysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03948c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a32844",
   "metadata": {},
   "source": [
    "## 1) Reading database and feature selection\n",
    "\n",
    "- The name of my database is final_covid, which is a selected part of main covid database.\n",
    "- All features with missing data exceeds 50% has been removed.\n",
    "- All feature values are numeric, some of them are categorical and some of them are continious.\n",
    "- Here we gonna select our feature based on ANOVA index and corresponding p-value for each feature per four outcomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fd5553e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Outcome_InhospitalMortality', 'Outcome_LOS', 'Outcome_ICUadmission', 'Outcome_ICULOS', 'Demographic_Age', 'Demographic_Gender', 'symtpm_to_referral', 'Symptom_Caugh', 'Symptom_Dyspnea', 'Symptom_Fever', 'Symptom_Chiver', 'Symptom_Mylagia', 'Symptom_Weakness', 'Symptom_LOC', 'Symptom_Sorethrough', 'Symptom_Rhinorrhea', 'Symptom_Smellingdisorder', 'Symptom_nauseaVomit', 'Symptom_Anorexia', 'Symptom_Diarhhea', 'Symptom_ChestPain', 'Symptom_Seizure', 'Symptom_SkinLesion', 'Symptom_Jointpain', 'Symptom_Headache', 'Symptom_AbdominalPain', 'Symptom_Earpain', 'Symptom_Hemorrhasia', 'Symptom_Hemiparesia', 'MH_Pregcy', 'MH_CurremtSmoker', 'MH_Alcoholuser', 'MH_Opiumuser', 'MH_Hookahuser', 'MH_HTN', 'MH_IHD', 'MH_CABG', 'MH_CHF', 'MH_Ashtma', 'MH_COPD', 'MH_DM', 'MH_Pneumonia', 'MH_CVA', 'MH_GIdisorder', 'MH_CKD', 'MH_RA', 'Cancer', 'MH_HLP', 'MH_HepC', 'MH_Thyroiddysfunction', 'MH_Immunocompromised', 'MH_ChronicSeizure', 'MH_TB', 'MH_Anemia', 'MH_Fattyliver', 'MH_Psychologicaldisorder', 'MH_Parkinson', 'MH_Alzhimer', 'VS_O2satwithoutsupp', 'VS_PR', 'VS_diastolicBP', 'VS_SystolicBP', 'VS_RR', 'VS_T', 'TM_S_Dialysis', 'TM_S_Wholeblood', 'TM_S_FFP/Platelet', 'TM_S_Intubation', 'TM_S_Plasmapheresis', 'TM_amantadin', 'TM_ASA', 'TM_atazonavir', 'TM_Atorvastatin', 'TM_Atrovent', 'TM_Azithromycin', 'TM_Bromhexine', 'TM_CaCo3', 'TM_Ceftriaxone', 'TM_Celexan', 'TM_Cilindamycin', 'TM_Ciprofloxacine', 'TM_ClidiniumC', 'TM_Combivent', 'TM_Dexamethasone', 'TM_Dextromethorphan', 'TM_Dimenhydranate', 'TM_Diphenhydramin', 'TM_Fluconazole', 'TM_Heparin', 'TM_hidroxycholoriquine', 'TM_imipenem', 'TM_Interferon', 'TM_kaletra', 'TM_Levofluxacin', 'TM_Linezolid', 'TM_Meropenem', 'TM_MgSo4', 'TM_NAC', 'TM_Ondancetrone', 'TM_oseltamivir', 'TM_piperacillin', 'TM_Plasil', 'TM_Plavix', 'TM_Prednisolone', 'TM_Promethazine', 'TM_Pulmi', 'TM_Ranitidin', 'TM_Remdesivir', 'TM_Ribavirin', 'TM_Salb', 'TM_Selenium', 'TM_Serflow', 'TM_sovodac', 'TM_Vanco', 'TM_VitB', 'TM_VitC', 'TM_VitD', 'TM_pantazole', 'TM_concor(bisoprolo)', 'TM_amilodiopine', 'TM_Aldactone', 'TM_lactalose', 'TM_carvidolol', 'TM_fentanyl', 'TM_apotel', 'TM_Zinc', 'TM_Insuline', 'TM_lasix', 'TM_Hematinic', 'TM_albumin', 'LAB_WBC_1', 'LAB_WBC_Final', 'LAB_LYMPHH_1', 'LAB_LYMPHH_Final', 'LAB_NEUT_1', 'LAB_NEUT_Final', 'LAB_PLT_1', 'LAB_PLT_Final', 'LAB_HB_1', 'LAB_HB_Final', 'LAB_MCV_1', 'LAB_MCV_Final', 'LAB_BUN_Final', 'LAB_CR_1', 'LAB_CR_Final', 'LAB_NA_First', 'LAB_NA_Final', 'LAB_K_First', 'LAB_K_Final', 'LAB_AST_Final', 'LAB_ALT_Final', 'LAB_ALKP_First', 'LAB_CRP_Final', 'LAB_ESR_First', 'LAB_CPK_First', 'LAB_PTT_First', 'LAB_PT_First', 'LAB_INR_First', 'LAB_PH_Final', 'LAB_HCO3_Final', 'LAB_BE_Final']\n"
     ]
    }
   ],
   "source": [
    "Data_frame = pd.read_csv ('final_data.csv')\n",
    "Data_columns = Data_frame.columns.tolist()\n",
    "print (Data_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fedbf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome_InhospitalMortality      79\n",
      "Outcome_LOS                       1\n",
      "Outcome_ICUadmission              0\n",
      "Outcome_ICULOS                    3\n",
      "Demographic_Age                   6\n",
      "                               ... \n",
      "LAB_PT_First                   4040\n",
      "LAB_INR_First                  4036\n",
      "LAB_PH_Final                   3291\n",
      "LAB_HCO3_Final                 3304\n",
      "LAB_BE_Final                   3539\n",
      "Length: 161, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Categorical_variables = [ 'Outcome_LOS', 'Outcome_ICULOS',  \n",
    "                         'Demographic_Gender', 'Symptom_Caugh', 'Symptom_Dyspnea', 'Symptom_Fever', 'Symptom_Chiver',\n",
    "                         'Symptom_Mylagia', 'Symptom_Weakness', 'Symptom_LOC', 'Symptom_Sorethrough', 'Symptom_Rhinorrhea',\n",
    "                         'Symptom_Smellingdisorder', 'Symptom_nauseaVomit', 'Symptom_Anorexia', 'Symptom_Diarhhea', 'Symptom_ChestPain',\n",
    "                         'Symptom_Seizure', 'Symptom_SkinLesion', 'Symptom_Jointpain', 'Symptom_Headache', 'Symptom_AbdominalPain',\n",
    "                         'Symptom_Earpain', 'Symptom_Hemorrhasia', 'Symptom_Hemiparesia', 'MH_Pregcy',\n",
    "                         'MH_CurremtSmoker', 'MH_Alcoholuser', 'MH_Opiumuser', 'MH_Hookahuser', 'MH_HTN', 'MH_IHD',\n",
    "                         'MH_CABG', 'MH_CHF', 'MH_Ashtma', 'MH_COPD', 'MH_DM', 'MH_Pneumonia', 'MH_CVA', 'MH_GIdisorder', 'MH_CKD', 'MH_RA',\n",
    "                         'Cancer', 'MH_HLP', 'MH_HepC', 'MH_Thyroiddysfunction', 'MH_Immunocompromised', 'MH_ChronicSeizure', 'MH_TB',\n",
    "                         'MH_Anemia', 'MH_Fattyliver', 'MH_Psychologicaldisorder', 'MH_Parkinson', 'MH_Alzhimer',   'TM_S_Wholeblood', 'TM_S_FFP/Platelet',\n",
    "                         'TM_S_Plasmapheresis', 'TM_amantadin', 'TM_ASA', 'TM_atazonavir', 'TM_Atorvastatin', 'TM_Atrovent',\n",
    "                         'TM_Azithromycin', 'TM_Bromhexine', 'TM_CaCo3', 'TM_Ceftriaxone', 'TM_Celexan', 'TM_Cilindamycin', 'TM_Ciprofloxacine',\n",
    "                         'TM_ClidiniumC', 'TM_Combivent', 'TM_Dexamethasone', 'TM_Dextromethorphan', 'TM_Dimenhydranate', 'TM_Diphenhydramin',\n",
    "                         'TM_Fluconazole', 'TM_Heparin', 'TM_hidroxycholoriquine', 'TM_imipenem', 'TM_Interferon', 'TM_kaletra', \n",
    "                         'TM_Levofluxacin', 'TM_Linezolid', 'TM_Meropenem', 'TM_MgSo4', 'TM_NAC', 'TM_Ondancetrone', 'TM_oseltamivir',\n",
    "                         'TM_piperacillin', 'TM_Plasil', 'TM_Plavix', 'TM_Prednisolone', 'TM_Promethazine', 'TM_Pulmi', 'TM_Ranitidin', \n",
    "                         'TM_Remdesivir', 'TM_Ribavirin', 'TM_Salb', 'TM_Selenium', 'TM_Serflow', 'TM_sovodac', 'TM_Vanco', 'TM_VitB', \n",
    "                         'TM_VitC', 'TM_VitD', 'TM_pantazole', 'TM_concor(bisoprolo)', 'TM_amilodiopine', 'TM_Aldactone', 'TM_lactalose',\n",
    "                         'TM_carvidolol', 'TM_fentanyl', 'TM_apotel', 'TM_Zinc', 'TM_Insuline', 'TM_lasix', 'TM_Hematinic', 'TM_albumin']\n",
    "\n",
    "Continious_variables = ['Demographic_Age','symtpm_to_referral','VS_O2satwithoutsupp',\n",
    "                         'VS_PR', 'VS_diastolicBP', 'VS_SystolicBP', 'VS_RR', 'VS_T','LAB_WBC_1', 'LAB_WBC_Final', 'LAB_LYMPHH_1',\n",
    "                         'LAB_LYMPHH_Final', 'LAB_NEUT_1', 'LAB_NEUT_Final', 'LAB_PLT_1', 'LAB_PLT_Final', 'LAB_HB_1', 'LAB_HB_Final',\n",
    "                         'LAB_MCV_1', 'LAB_MCV_Final', 'LAB_BUN_Final', 'LAB_CR_1', 'LAB_CR_Final', 'LAB_NA_First', 'LAB_NA_Final', \n",
    "                         'LAB_K_First', 'LAB_K_Final', 'LAB_AST_Final', 'LAB_ALT_Final', 'LAB_ALKP_First', 'LAB_CRP_Final', 'LAB_ESR_First',\n",
    "                         'LAB_CPK_First', 'LAB_PTT_First', 'LAB_PT_First', 'LAB_INR_First', 'LAB_PH_Final', 'LAB_HCO3_Final', 'LAB_BE_Final' ]\n",
    "\n",
    "Output_features = ['Outcome_InhospitalMortality','Outcome_ICUadmission','TM_S_Dialysis','TM_S_Intubation']\n",
    "\n",
    "missing_counts = Data_frame.isnull().sum()\n",
    "print(missing_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8e020e",
   "metadata": {},
   "source": [
    "## 1-1) Imputaion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2b6608d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome_InhospitalMortality    79\n",
      "Outcome_LOS                     0\n",
      "Outcome_ICUadmission            0\n",
      "Outcome_ICULOS                  0\n",
      "Demographic_Age                 0\n",
      "                               ..\n",
      "LAB_PT_First                    0\n",
      "LAB_INR_First                   0\n",
      "LAB_PH_Final                    0\n",
      "LAB_HCO3_Final                  0\n",
      "LAB_BE_Final                    0\n",
      "Length: 161, dtype: int64\n",
      "Outcome_InhospitalMortality    0\n",
      "Outcome_ICUadmission           0\n",
      "TM_S_Dialysis                  0\n",
      "TM_S_Intubation                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp_cat = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imp_cat.fit(Data_frame [Categorical_variables])\n",
    "Data_frame [Categorical_variables] = imp_cat.transform(Data_frame [Categorical_variables])\n",
    "\n",
    "imp_con = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_con.fit(Data_frame [Continious_variables])\n",
    "Data_frame [Continious_variables] = imp_con.transform(Data_frame [Continious_variables])\n",
    "\n",
    "missing_counts = Data_frame.isnull().sum()\n",
    "print(missing_counts)\n",
    "\n",
    "Data_frame.dropna(subset=['Outcome_InhospitalMortality'], inplace=True)\n",
    "\n",
    "missing_outcomes = Data_frame[Output_features].isnull().sum()\n",
    "print(missing_outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6e3a7f",
   "metadata": {},
   "source": [
    "## 1-2) feature selection \n",
    "\n",
    "- ANOVA index and corresponding p-value will calcualted for all features\n",
    "- a higher F-value and a lower p-value generally indicate a stronger relationship between a feature and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "822fb394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Separate the features and outputs\n",
    "X = Data_frame.drop(columns= Output_features)\n",
    "list_of_FS = list ()\n",
    "\n",
    "\n",
    "for i in Output_features:\n",
    "    y = Data_frame [i] \n",
    "    f_values, p_values = f_classif(X, y)\n",
    "    anova_results = pd.DataFrame({'Feature': X.columns, 'F-value': f_values, 'p-value': p_values})\n",
    "    anova_results = anova_results.sort_values('p-value')\n",
    "    anova_results.to_csv('anova_results.csv',mode='a', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90d54abc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mortality</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>ICU admission</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Dialysis</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Intubation</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feature</td>\n",
       "      <td>F-value</td>\n",
       "      <td>p-value</td>\n",
       "      <td>Feature</td>\n",
       "      <td>F-value</td>\n",
       "      <td>p-value</td>\n",
       "      <td>Feature</td>\n",
       "      <td>F-value</td>\n",
       "      <td>p-value</td>\n",
       "      <td>Feature</td>\n",
       "      <td>F-value</td>\n",
       "      <td>p-value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAB_BUN_Final</td>\n",
       "      <td>2058.804293</td>\n",
       "      <td>0</td>\n",
       "      <td>Outcome_ICULOS</td>\n",
       "      <td>7306.190251</td>\n",
       "      <td>0</td>\n",
       "      <td>LAB_CR_Final</td>\n",
       "      <td>2454.75419</td>\n",
       "      <td>0</td>\n",
       "      <td>TM_fentanyl</td>\n",
       "      <td>1109.408235</td>\n",
       "      <td>1.43E-229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TM_fentanyl</td>\n",
       "      <td>1324.86435</td>\n",
       "      <td>7.56E-271</td>\n",
       "      <td>Outcome_LOS</td>\n",
       "      <td>720.5735977</td>\n",
       "      <td>8.59E-153</td>\n",
       "      <td>LAB_CR_1</td>\n",
       "      <td>2313.904381</td>\n",
       "      <td>0</td>\n",
       "      <td>Outcome_ICULOS</td>\n",
       "      <td>1090.714903</td>\n",
       "      <td>6.00E-226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAB_BE_Final</td>\n",
       "      <td>1171.276988</td>\n",
       "      <td>1.63E-241</td>\n",
       "      <td>TM_fentanyl</td>\n",
       "      <td>688.2411039</td>\n",
       "      <td>2.86E-146</td>\n",
       "      <td>MH_CKD</td>\n",
       "      <td>970.5738127</td>\n",
       "      <td>1.67E-202</td>\n",
       "      <td>LAB_BUN_Final</td>\n",
       "      <td>559.7292012</td>\n",
       "      <td>4.04E-120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TM_Vanco</td>\n",
       "      <td>1112.854332</td>\n",
       "      <td>3.08E-230</td>\n",
       "      <td>TM_Vanco</td>\n",
       "      <td>537.9690024</td>\n",
       "      <td>1.17E-115</td>\n",
       "      <td>LAB_BUN_Final</td>\n",
       "      <td>439.1439102</td>\n",
       "      <td>2.96E-95</td>\n",
       "      <td>VS_O2satwithoutsupp</td>\n",
       "      <td>536.6455809</td>\n",
       "      <td>2.19E-115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Demographic_Age</td>\n",
       "      <td>938.6322921</td>\n",
       "      <td>3.19E-196</td>\n",
       "      <td>VS_O2satwithoutsupp</td>\n",
       "      <td>466.3672472</td>\n",
       "      <td>6.75E-101</td>\n",
       "      <td>TM_S_Wholeblood</td>\n",
       "      <td>371.1384088</td>\n",
       "      <td>4.38E-81</td>\n",
       "      <td>TM_Vanco</td>\n",
       "      <td>502.7223704</td>\n",
       "      <td>2.09E-108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VS_O2satwithoutsupp</td>\n",
       "      <td>919.7428278</td>\n",
       "      <td>1.69E-192</td>\n",
       "      <td>LAB_BUN_Final</td>\n",
       "      <td>387.7472043</td>\n",
       "      <td>1.48E-84</td>\n",
       "      <td>LAB_BE_Final</td>\n",
       "      <td>336.8912518</td>\n",
       "      <td>6.58E-74</td>\n",
       "      <td>TM_Meropenem</td>\n",
       "      <td>374.5286835</td>\n",
       "      <td>8.56E-82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LAB_CR_Final</td>\n",
       "      <td>851.7615128</td>\n",
       "      <td>4.89E-179</td>\n",
       "      <td>TM_NAC</td>\n",
       "      <td>318.9580735</td>\n",
       "      <td>3.87E-70</td>\n",
       "      <td>TM_CaCo3</td>\n",
       "      <td>285.1218608</td>\n",
       "      <td>5.26E-63</td>\n",
       "      <td>LAB_BE_Final</td>\n",
       "      <td>335.0055261</td>\n",
       "      <td>1.64E-73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Outcome_ICULOS</td>\n",
       "      <td>844.9844776</td>\n",
       "      <td>1.09E-177</td>\n",
       "      <td>TM_S_Wholeblood</td>\n",
       "      <td>241.4075021</td>\n",
       "      <td>9.56E-54</td>\n",
       "      <td>LAB_HB_Final</td>\n",
       "      <td>252.6324717</td>\n",
       "      <td>3.96E-56</td>\n",
       "      <td>Symptom_LOC</td>\n",
       "      <td>301.0953127</td>\n",
       "      <td>2.24E-66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LAB_HCO3_Final</td>\n",
       "      <td>791.1816984</td>\n",
       "      <td>5.81E-167</td>\n",
       "      <td>TM_lasix</td>\n",
       "      <td>241.0637353</td>\n",
       "      <td>1.13E-53</td>\n",
       "      <td>TM_Vanco</td>\n",
       "      <td>237.7861831</td>\n",
       "      <td>5.62E-53</td>\n",
       "      <td>LAB_LYMPHH_Final</td>\n",
       "      <td>246.7472524</td>\n",
       "      <td>7.02E-55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LAB_NEUT_Final</td>\n",
       "      <td>759.9219954</td>\n",
       "      <td>1.06E-160</td>\n",
       "      <td>LAB_LYMPHH_Final</td>\n",
       "      <td>209.3625987</td>\n",
       "      <td>6.30E-47</td>\n",
       "      <td>LAB_HCO3_Final</td>\n",
       "      <td>231.4134375</td>\n",
       "      <td>1.27E-51</td>\n",
       "      <td>Outcome_LOS</td>\n",
       "      <td>236.168182</td>\n",
       "      <td>1.24E-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LAB_LYMPHH_Final</td>\n",
       "      <td>709.7432253</td>\n",
       "      <td>1.31E-150</td>\n",
       "      <td>LAB_WBC_Final</td>\n",
       "      <td>208.267382</td>\n",
       "      <td>1.08E-46</td>\n",
       "      <td>TM_fentanyl</td>\n",
       "      <td>206.1058398</td>\n",
       "      <td>3.12E-46</td>\n",
       "      <td>LAB_NEUT_Final</td>\n",
       "      <td>231.7062793</td>\n",
       "      <td>1.10E-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Symptom_LOC</td>\n",
       "      <td>696.2573178</td>\n",
       "      <td>6.88E-148</td>\n",
       "      <td>TM_Prednisolone</td>\n",
       "      <td>201.8963197</td>\n",
       "      <td>2.47E-45</td>\n",
       "      <td>LAB_HB_1</td>\n",
       "      <td>164.8012495</td>\n",
       "      <td>2.14E-37</td>\n",
       "      <td>LAB_CR_Final</td>\n",
       "      <td>226.2307264</td>\n",
       "      <td>1.61E-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LAB_CRP_Final</td>\n",
       "      <td>623.2157281</td>\n",
       "      <td>4.40E-133</td>\n",
       "      <td>TM_Meropenem</td>\n",
       "      <td>187.6209124</td>\n",
       "      <td>2.77E-42</td>\n",
       "      <td>TM_amilodiopine</td>\n",
       "      <td>146.4489904</td>\n",
       "      <td>1.88E-33</td>\n",
       "      <td>LAB_HCO3_Final</td>\n",
       "      <td>223.6720069</td>\n",
       "      <td>5.64E-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TM_Meropenem</td>\n",
       "      <td>499.6168433</td>\n",
       "      <td>9.14E-108</td>\n",
       "      <td>TM_Remdesivir</td>\n",
       "      <td>172.7111923</td>\n",
       "      <td>4.31E-39</td>\n",
       "      <td>Outcome_ICULOS</td>\n",
       "      <td>144.1125237</td>\n",
       "      <td>5.97E-33</td>\n",
       "      <td>Demographic_Age</td>\n",
       "      <td>193.1873545</td>\n",
       "      <td>1.79E-43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LAB_WBC_Final</td>\n",
       "      <td>447.4157797</td>\n",
       "      <td>5.69E-97</td>\n",
       "      <td>LAB_NEUT_1</td>\n",
       "      <td>166.5278286</td>\n",
       "      <td>9.12E-38</td>\n",
       "      <td>LAB_K_Final</td>\n",
       "      <td>141.8790399</td>\n",
       "      <td>1.81E-32</td>\n",
       "      <td>LAB_PH_Final</td>\n",
       "      <td>181.0147881</td>\n",
       "      <td>7.18E-41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LAB_PLT_Final</td>\n",
       "      <td>384.997573</td>\n",
       "      <td>5.56E-84</td>\n",
       "      <td>LAB_LYMPHH_1</td>\n",
       "      <td>163.2879744</td>\n",
       "      <td>4.52E-37</td>\n",
       "      <td>Outcome_LOS</td>\n",
       "      <td>139.269388</td>\n",
       "      <td>6.58E-32</td>\n",
       "      <td>TM_S_Wholeblood</td>\n",
       "      <td>177.7562684</td>\n",
       "      <td>3.58E-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LAB_PH_Final</td>\n",
       "      <td>346.0278343</td>\n",
       "      <td>7.96E-76</td>\n",
       "      <td>LAB_NEUT_Final</td>\n",
       "      <td>161.7013173</td>\n",
       "      <td>9.90E-37</td>\n",
       "      <td>TM_Meropenem</td>\n",
       "      <td>119.6211558</td>\n",
       "      <td>1.14E-27</td>\n",
       "      <td>LAB_WBC_Final</td>\n",
       "      <td>175.9593869</td>\n",
       "      <td>8.68E-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TM_S_Wholeblood</td>\n",
       "      <td>326.9187801</td>\n",
       "      <td>8.19E-72</td>\n",
       "      <td>TM_imipenem</td>\n",
       "      <td>142.8974503</td>\n",
       "      <td>1.09E-32</td>\n",
       "      <td>TM_Linezolid</td>\n",
       "      <td>94.06753659</td>\n",
       "      <td>3.91E-22</td>\n",
       "      <td>LAB_CRP_Final</td>\n",
       "      <td>163.8108155</td>\n",
       "      <td>3.49E-37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LAB_K_Final</td>\n",
       "      <td>323.7651289</td>\n",
       "      <td>3.77E-71</td>\n",
       "      <td>TM_Ciprofloxacine</td>\n",
       "      <td>138.5794282</td>\n",
       "      <td>9.27E-32</td>\n",
       "      <td>TM_Heparin</td>\n",
       "      <td>91.79522638</td>\n",
       "      <td>1.22E-21</td>\n",
       "      <td>TM_NAC</td>\n",
       "      <td>121.9093658</td>\n",
       "      <td>3.65E-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TM_lasix</td>\n",
       "      <td>322.8085362</td>\n",
       "      <td>5.99E-71</td>\n",
       "      <td>Symptom_LOC</td>\n",
       "      <td>133.6689897</td>\n",
       "      <td>1.06E-30</td>\n",
       "      <td>MH_HTN</td>\n",
       "      <td>91.59147565</td>\n",
       "      <td>1.35E-21</td>\n",
       "      <td>LAB_LYMPHH_1</td>\n",
       "      <td>119.1710628</td>\n",
       "      <td>1.43E-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LAB_NEUT_1</td>\n",
       "      <td>298.3814327</td>\n",
       "      <td>8.36E-66</td>\n",
       "      <td>Demographic_Age</td>\n",
       "      <td>129.3043068</td>\n",
       "      <td>9.26E-30</td>\n",
       "      <td>LAB_PLT_Final</td>\n",
       "      <td>87.6654365</td>\n",
       "      <td>9.62E-21</td>\n",
       "      <td>LAB_NEUT_1</td>\n",
       "      <td>114.5867419</td>\n",
       "      <td>1.40E-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LAB_LYMPHH_1</td>\n",
       "      <td>270.5252691</td>\n",
       "      <td>6.42E-60</td>\n",
       "      <td>LAB_BE_Final</td>\n",
       "      <td>125.5447935</td>\n",
       "      <td>5.99E-29</td>\n",
       "      <td>TM_lasix</td>\n",
       "      <td>85.42697492</td>\n",
       "      <td>2.95E-20</td>\n",
       "      <td>TM_Ciprofloxacine</td>\n",
       "      <td>112.3314921</td>\n",
       "      <td>4.30E-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LAB_AST_Final</td>\n",
       "      <td>257.8170691</td>\n",
       "      <td>3.15E-57</td>\n",
       "      <td>TM_Heparin</td>\n",
       "      <td>125.2618452</td>\n",
       "      <td>6.90E-29</td>\n",
       "      <td>TM_S_FFP/Platelet</td>\n",
       "      <td>75.33757744</td>\n",
       "      <td>4.66E-18</td>\n",
       "      <td>LAB_PLT_Final</td>\n",
       "      <td>110.4024144</td>\n",
       "      <td>1.12E-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LAB_HB_Final</td>\n",
       "      <td>237.5452892</td>\n",
       "      <td>6.32E-53</td>\n",
       "      <td>LAB_CR_Final</td>\n",
       "      <td>118.038375</td>\n",
       "      <td>2.51E-27</td>\n",
       "      <td>LAB_CRP_Final</td>\n",
       "      <td>66.83721664</td>\n",
       "      <td>3.35E-16</td>\n",
       "      <td>TM_Linezolid</td>\n",
       "      <td>108.6837968</td>\n",
       "      <td>2.65E-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LAB_NA_Final</td>\n",
       "      <td>233.042224</td>\n",
       "      <td>5.72E-52</td>\n",
       "      <td>TM_VitC</td>\n",
       "      <td>116.4128006</td>\n",
       "      <td>5.63E-27</td>\n",
       "      <td>TM_lactalose</td>\n",
       "      <td>64.34559</td>\n",
       "      <td>1.17E-15</td>\n",
       "      <td>TM_Prednisolone</td>\n",
       "      <td>90.4162883</td>\n",
       "      <td>2.43E-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LAB_CR_1</td>\n",
       "      <td>211.3370476</td>\n",
       "      <td>2.39E-47</td>\n",
       "      <td>TM_Dexamethasone</td>\n",
       "      <td>114.8121511</td>\n",
       "      <td>1.25E-26</td>\n",
       "      <td>TM_imipenem</td>\n",
       "      <td>59.41477738</td>\n",
       "      <td>1.41E-14</td>\n",
       "      <td>LAB_HB_Final</td>\n",
       "      <td>85.49464851</td>\n",
       "      <td>2.85E-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TM_Ciprofloxacine</td>\n",
       "      <td>167.2638174</td>\n",
       "      <td>6.34E-38</td>\n",
       "      <td>TM_VitD</td>\n",
       "      <td>106.3779329</td>\n",
       "      <td>8.36E-25</td>\n",
       "      <td>LAB_PH_Final</td>\n",
       "      <td>58.80106763</td>\n",
       "      <td>1.92E-14</td>\n",
       "      <td>LAB_NA_Final</td>\n",
       "      <td>81.18319762</td>\n",
       "      <td>2.48E-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MH_HTN</td>\n",
       "      <td>161.3235305</td>\n",
       "      <td>1.19E-36</td>\n",
       "      <td>LAB_PH_Final</td>\n",
       "      <td>101.3890226</td>\n",
       "      <td>1.01E-23</td>\n",
       "      <td>TM_Ciprofloxacine</td>\n",
       "      <td>57.83947394</td>\n",
       "      <td>3.13E-14</td>\n",
       "      <td>TM_Fluconazole</td>\n",
       "      <td>77.97527691</td>\n",
       "      <td>1.24E-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MH_CVA</td>\n",
       "      <td>161.0849186</td>\n",
       "      <td>1.34E-36</td>\n",
       "      <td>TM_S_FFP/Platelet</td>\n",
       "      <td>94.52879985</td>\n",
       "      <td>3.10E-22</td>\n",
       "      <td>MH_DM</td>\n",
       "      <td>54.08067561</td>\n",
       "      <td>2.09E-13</td>\n",
       "      <td>LAB_K_Final</td>\n",
       "      <td>71.68236725</td>\n",
       "      <td>2.92E-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mortality   Unnamed: 1 Unnamed: 2       ICU admission   \\\n",
       "0               Feature      F-value    p-value              Feature   \n",
       "1         LAB_BUN_Final  2058.804293          0       Outcome_ICULOS   \n",
       "2           TM_fentanyl   1324.86435  7.56E-271          Outcome_LOS   \n",
       "3          LAB_BE_Final  1171.276988  1.63E-241          TM_fentanyl   \n",
       "4              TM_Vanco  1112.854332  3.08E-230             TM_Vanco   \n",
       "5       Demographic_Age  938.6322921  3.19E-196  VS_O2satwithoutsupp   \n",
       "6   VS_O2satwithoutsupp  919.7428278  1.69E-192        LAB_BUN_Final   \n",
       "7          LAB_CR_Final  851.7615128  4.89E-179               TM_NAC   \n",
       "8        Outcome_ICULOS  844.9844776  1.09E-177      TM_S_Wholeblood   \n",
       "9        LAB_HCO3_Final  791.1816984  5.81E-167             TM_lasix   \n",
       "10       LAB_NEUT_Final  759.9219954  1.06E-160     LAB_LYMPHH_Final   \n",
       "11     LAB_LYMPHH_Final  709.7432253  1.31E-150        LAB_WBC_Final   \n",
       "12          Symptom_LOC  696.2573178  6.88E-148      TM_Prednisolone   \n",
       "13        LAB_CRP_Final  623.2157281  4.40E-133         TM_Meropenem   \n",
       "14         TM_Meropenem  499.6168433  9.14E-108        TM_Remdesivir   \n",
       "15        LAB_WBC_Final  447.4157797   5.69E-97           LAB_NEUT_1   \n",
       "16        LAB_PLT_Final   384.997573   5.56E-84         LAB_LYMPHH_1   \n",
       "17         LAB_PH_Final  346.0278343   7.96E-76       LAB_NEUT_Final   \n",
       "18      TM_S_Wholeblood  326.9187801   8.19E-72          TM_imipenem   \n",
       "19          LAB_K_Final  323.7651289   3.77E-71    TM_Ciprofloxacine   \n",
       "20             TM_lasix  322.8085362   5.99E-71          Symptom_LOC   \n",
       "21           LAB_NEUT_1  298.3814327   8.36E-66      Demographic_Age   \n",
       "22         LAB_LYMPHH_1  270.5252691   6.42E-60         LAB_BE_Final   \n",
       "23        LAB_AST_Final  257.8170691   3.15E-57           TM_Heparin   \n",
       "24         LAB_HB_Final  237.5452892   6.32E-53         LAB_CR_Final   \n",
       "25         LAB_NA_Final   233.042224   5.72E-52              TM_VitC   \n",
       "26             LAB_CR_1  211.3370476   2.39E-47     TM_Dexamethasone   \n",
       "27    TM_Ciprofloxacine  167.2638174   6.34E-38              TM_VitD   \n",
       "28               MH_HTN  161.3235305   1.19E-36         LAB_PH_Final   \n",
       "29               MH_CVA  161.0849186   1.34E-36    TM_S_FFP/Platelet   \n",
       "\n",
       "     Unnamed: 4 Unnamed: 5           Dialysis   Unnamed: 7 Unnamed: 8  \\\n",
       "0       F-value    p-value            Feature      F-value    p-value   \n",
       "1   7306.190251          0       LAB_CR_Final   2454.75419          0   \n",
       "2   720.5735977  8.59E-153           LAB_CR_1  2313.904381          0   \n",
       "3   688.2411039  2.86E-146             MH_CKD  970.5738127  1.67E-202   \n",
       "4   537.9690024  1.17E-115      LAB_BUN_Final  439.1439102   2.96E-95   \n",
       "5   466.3672472  6.75E-101    TM_S_Wholeblood  371.1384088   4.38E-81   \n",
       "6   387.7472043   1.48E-84       LAB_BE_Final  336.8912518   6.58E-74   \n",
       "7   318.9580735   3.87E-70           TM_CaCo3  285.1218608   5.26E-63   \n",
       "8   241.4075021   9.56E-54       LAB_HB_Final  252.6324717   3.96E-56   \n",
       "9   241.0637353   1.13E-53           TM_Vanco  237.7861831   5.62E-53   \n",
       "10  209.3625987   6.30E-47     LAB_HCO3_Final  231.4134375   1.27E-51   \n",
       "11   208.267382   1.08E-46        TM_fentanyl  206.1058398   3.12E-46   \n",
       "12  201.8963197   2.47E-45           LAB_HB_1  164.8012495   2.14E-37   \n",
       "13  187.6209124   2.77E-42    TM_amilodiopine  146.4489904   1.88E-33   \n",
       "14  172.7111923   4.31E-39     Outcome_ICULOS  144.1125237   5.97E-33   \n",
       "15  166.5278286   9.12E-38        LAB_K_Final  141.8790399   1.81E-32   \n",
       "16  163.2879744   4.52E-37        Outcome_LOS   139.269388   6.58E-32   \n",
       "17  161.7013173   9.90E-37       TM_Meropenem  119.6211558   1.14E-27   \n",
       "18  142.8974503   1.09E-32       TM_Linezolid  94.06753659   3.91E-22   \n",
       "19  138.5794282   9.27E-32         TM_Heparin  91.79522638   1.22E-21   \n",
       "20  133.6689897   1.06E-30             MH_HTN  91.59147565   1.35E-21   \n",
       "21  129.3043068   9.26E-30      LAB_PLT_Final   87.6654365   9.62E-21   \n",
       "22  125.5447935   5.99E-29           TM_lasix  85.42697492   2.95E-20   \n",
       "23  125.2618452   6.90E-29  TM_S_FFP/Platelet  75.33757744   4.66E-18   \n",
       "24   118.038375   2.51E-27      LAB_CRP_Final  66.83721664   3.35E-16   \n",
       "25  116.4128006   5.63E-27       TM_lactalose     64.34559   1.17E-15   \n",
       "26  114.8121511   1.25E-26        TM_imipenem  59.41477738   1.41E-14   \n",
       "27  106.3779329   8.36E-25       LAB_PH_Final  58.80106763   1.92E-14   \n",
       "28  101.3890226   1.01E-23  TM_Ciprofloxacine  57.83947394   3.13E-14   \n",
       "29  94.52879985   3.10E-22              MH_DM  54.08067561   2.09E-13   \n",
       "\n",
       "             Intubation  Unnamed: 10 Unnamed: 11  \n",
       "0               Feature      F-value     p-value  \n",
       "1           TM_fentanyl  1109.408235   1.43E-229  \n",
       "2        Outcome_ICULOS  1090.714903   6.00E-226  \n",
       "3         LAB_BUN_Final  559.7292012   4.04E-120  \n",
       "4   VS_O2satwithoutsupp  536.6455809   2.19E-115  \n",
       "5              TM_Vanco  502.7223704   2.09E-108  \n",
       "6          TM_Meropenem  374.5286835    8.56E-82  \n",
       "7          LAB_BE_Final  335.0055261    1.64E-73  \n",
       "8           Symptom_LOC  301.0953127    2.24E-66  \n",
       "9      LAB_LYMPHH_Final  246.7472524    7.02E-55  \n",
       "10          Outcome_LOS   236.168182    1.24E-52  \n",
       "11       LAB_NEUT_Final  231.7062793    1.10E-51  \n",
       "12         LAB_CR_Final  226.2307264    1.61E-50  \n",
       "13       LAB_HCO3_Final  223.6720069    5.64E-50  \n",
       "14      Demographic_Age  193.1873545    1.79E-43  \n",
       "15         LAB_PH_Final  181.0147881    7.18E-41  \n",
       "16      TM_S_Wholeblood  177.7562684    3.58E-40  \n",
       "17        LAB_WBC_Final  175.9593869    8.68E-40  \n",
       "18        LAB_CRP_Final  163.8108155    3.49E-37  \n",
       "19               TM_NAC  121.9093658    3.65E-28  \n",
       "20         LAB_LYMPHH_1  119.1710628    1.43E-27  \n",
       "21           LAB_NEUT_1  114.5867419    1.40E-26  \n",
       "22    TM_Ciprofloxacine  112.3314921    4.30E-26  \n",
       "23        LAB_PLT_Final  110.4024144    1.12E-25  \n",
       "24         TM_Linezolid  108.6837968    2.65E-25  \n",
       "25      TM_Prednisolone   90.4162883    2.43E-21  \n",
       "26         LAB_HB_Final  85.49464851    2.85E-20  \n",
       "27         LAB_NA_Final  81.18319762    2.48E-19  \n",
       "28       TM_Fluconazole  77.97527691    1.24E-18  \n",
       "29          LAB_K_Final  71.68236725    2.92E-17  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the feature rankings\n",
    "from IPython.display import display\n",
    "df = pd.read_csv('anova_results.csv')\n",
    "\n",
    "# Display the DataFrame as a table\n",
    "display(df.head (30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b417a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LAB_LYMPHH_1', 'VS_O2satwithoutsupp', 'MH_DM', 'LAB_CR_1', 'MH_Alzhimer', 'LAB_CRP_Final', 'LAB_LYMPHH_Final', 'Symptom_LOC', 'LAB_PLT_Final', 'Cancer', 'LAB_AST_Final', 'LAB_BUN_Final', 'MH_IHD', 'LAB_NEUT_1', 'MH_CVA', 'LAB_PH_Final', 'LAB_WBC_Final', 'Outcome_LOS', 'LAB_NEUT_Final', 'LAB_HB_1', 'LAB_HCO3_Final', 'LAB_K_Final', 'LAB_HB_Final', 'MH_CKD', 'Demographic_Age', 'LAB_BE_Final', 'Outcome_ICULOS', 'MH_HTN', 'LAB_CR_Final', 'VS_PR', 'LAB_NA_Final', 'VS_RR']\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "pre_Final_features = ['LAB_BUN_Final','LAB_BUN_Final', 'LAB_BE_Final', 'Demographic_Age',\n",
    "                      'VS_O2satwithoutsupp', 'LAB_CR_Final', 'Outcome_ICULOS', 'LAB_HCO3_Final', 'LAB_NEUT_Final',\n",
    "                      'LAB_LYMPHH_Final','Symptom_LOC', 'LAB_CRP_Final', 'Outcome_ICULOS', 'Outcome_LOS', \n",
    "                      'VS_O2satwithoutsupp', 'LAB_BUN_Final',\n",
    "                      'LAB_LYMPHH_Final', 'LAB_WBC_Final', 'LAB_CR_Final', 'LAB_CR_1',\n",
    "                      'MH_CKD', 'LAB_BUN_Final', 'LAB_BE_Final', 'LAB_HB_Final',\n",
    "                      'LAB_HCO3_Final',  'LAB_HB_1',\n",
    "                      'Outcome_ICULOS', 'LAB_BUN_Final', 'VS_O2satwithoutsupp','LAB_BE_Final',\n",
    "                      'Symptom_LOC', 'LAB_LYMPHH_Final', 'Outcome_LOS', 'LAB_NEUT_Final', 'LAB_CR_Final','LAB_HCO3_Final',\n",
    "                      'LAB_WBC_Final','LAB_PLT_Final', 'LAB_PH_Final', 'LAB_K_Final', 'LAB_NEUT_1', 'LAB_LYMPHH_1',\n",
    "                      'LAB_AST_Final', 'LAB_HB_Final', 'LAB_NA_Final', 'LAB_CR_1', 'MH_HTN', 'LAB_NEUT_1', 'LAB_LYMPHH_1', \n",
    "                      'LAB_NEUT_Final', 'Symptom_LOC', 'Demographic_Age', 'LAB_BE_Final', 'LAB_CR_Final', 'LAB_PH_Final',\n",
    "                      'Outcome_ICULOS', 'LAB_K_Final', 'Outcome_LOS', 'MH_HTN', 'LAB_PLT_Final', 'LAB_CRP_Final', \n",
    "                      'LAB_PH_Final', 'Demographic_Age', 'LAB_PH_Final', 'LAB_WBC_Final', 'LAB_CRP_Final',\n",
    "                      'LAB_LYMPHH_1', 'LAB_NEUT_1', 'LAB_PLT_Final',\n",
    "                      'LAB_HB_Final', 'LAB_NA_Final', 'MH_CVA', 'MH_DM', 'LAB_AST_Final', 'VS_PR', 'LAB_PLT_Final','Cancer',\n",
    "                      'MH_Alzhimer','MH_IHD', 'VS_RR' ]\n",
    "\n",
    "Final_features = list(set(pre_Final_features))\n",
    "Total_features = Final_features + Output_features\n",
    "cdf = Data_frame [Total_features]\n",
    "print (Final_features)\n",
    "print (len (Final_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049745c1",
   "metadata": {},
   "source": [
    "## 2)  Data selection and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5de51b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data selection and (the first) preprocessing\n",
    "\n",
    "X = np.asarray (cdf [Final_features])\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "y = np.asarray (cdf [Output_features])\n",
    "\n",
    "X = X.astype('float32')\n",
    "y = y.astype('float32')\n",
    "\n",
    "# train/test split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split (X,y,test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c91ab0",
   "metadata": {},
   "source": [
    "## 3) Hypervariable\n",
    "\n",
    "- Hypervariable determination is necessary before model developement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e77a1c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to know haw many layers and how many neurons in each layer would have the best function\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "def creat_model (nl=1, nn=512):\n",
    "    model = Sequential ()\n",
    "    model.add (Dense (256, input_shape = (32,), activation = 'relu'))\n",
    "    for i in range (nl):\n",
    "        model.add (Dense (nn, activation = 'relu'))\n",
    "    model.add (Dense (4, activation = 'sigmoid'))\n",
    "    model.compile (optimizer='adam', loss = BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fb0ccf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_11080\\2945637925.py:5: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=creat_model, epochs=6, batch_size=512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "12/12 [==============================] - 3s 87ms/step - loss: 0.4244 - accuracy: 0.7654\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 0.2551 - accuracy: 0.9254\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 1s 93ms/step - loss: 0.2341 - accuracy: 0.9254\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 1s 96ms/step - loss: 0.2229 - accuracy: 0.9152\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 1s 96ms/step - loss: 0.1929 - accuracy: 0.8809\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 1s 96ms/step - loss: 0.1789 - accuracy: 0.8885\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2011 - accuracy: 0.8728\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 3s 96ms/step - loss: 0.4587 - accuracy: 0.6967\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 1s 94ms/step - loss: 0.2768 - accuracy: 0.4144\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 1s 96ms/step - loss: 0.2509 - accuracy: 0.9024\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 1s 100ms/step - loss: 0.2305 - accuracy: 0.9024\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 1s 101ms/step - loss: 0.2042 - accuracy: 0.8517\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 1s 101ms/step - loss: 0.1864 - accuracy: 0.8660\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.2187 - accuracy: 0.8738\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 3s 91ms/step - loss: 0.4685 - accuracy: 0.4959\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 1s 97ms/step - loss: 0.2624 - accuracy: 0.1938\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 1s 99ms/step - loss: 0.2330 - accuracy: 0.9210\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 1s 101ms/step - loss: 0.2195 - accuracy: 0.9210\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 1s 100ms/step - loss: 0.2011 - accuracy: 0.8769\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.1826 - accuracy: 0.8779\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2288 - accuracy: 0.8883\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 1s 7ms/step - loss: 0.6114 - accuracy: 0.0658\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3604 - accuracy: 0.5674\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2748 - accuracy: 0.7869\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2528 - accuracy: 0.7541\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2389 - accuracy: 0.9254\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2231 - accuracy: 0.9254\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.2306 - accuracy: 0.8943\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 2s 8ms/step - loss: 0.6633 - accuracy: 0.0765\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4320 - accuracy: 0.3114\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2977 - accuracy: 0.3869\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2640 - accuracy: 0.2589\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2297 - accuracy: 0.8009\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2002 - accuracy: 0.8615\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.2019 - accuracy: 0.8804\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 1s 6ms/step - loss: 0.6315 - accuracy: 0.0371\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3566 - accuracy: 0.4539\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2740 - accuracy: 0.6969\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2485 - accuracy: 0.1936\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2317 - accuracy: 0.6546\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2158 - accuracy: 0.3139\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2791 - accuracy: 0.1799\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 11s 716ms/step - loss: 2.9424 - accuracy: 0.7752\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 8s 680ms/step - loss: 0.4596 - accuracy: 0.9254\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 8s 694ms/step - loss: 0.3429 - accuracy: 0.9254\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 9s 715ms/step - loss: 0.2768 - accuracy: 0.9254\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 8s 706ms/step - loss: 0.2342 - accuracy: 0.9001\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 9s 714ms/step - loss: 0.1998 - accuracy: 0.8870\n",
      "6/6 [==============================] - 1s 170ms/step - loss: 0.2206 - accuracy: 0.8748\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 10s 694ms/step - loss: 1.6636 - accuracy: 0.8324\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 8s 704ms/step - loss: 0.3898 - accuracy: 0.4875\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 8s 706ms/step - loss: 0.2976 - accuracy: 0.3454\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 8s 703ms/step - loss: 0.2468 - accuracy: 0.8547\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 8s 702ms/step - loss: 0.2137 - accuracy: 0.8501\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 9s 712ms/step - loss: 0.2075 - accuracy: 0.8730\n",
      "6/6 [==============================] - 1s 160ms/step - loss: 0.2018 - accuracy: 0.8976\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 10s 691ms/step - loss: 7.9140 - accuracy: 0.9210\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 8s 704ms/step - loss: 0.4419 - accuracy: 0.9210\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 9s 721ms/step - loss: 0.3229 - accuracy: 0.9210\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 8s 695ms/step - loss: 0.2432 - accuracy: 0.4817\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 8s 692ms/step - loss: 0.2242 - accuracy: 0.5335\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 8s 694ms/step - loss: 0.2045 - accuracy: 0.6775\n",
      "6/6 [==============================] - 1s 160ms/step - loss: 0.2733 - accuracy: 0.5003\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 2s 31ms/step - loss: 0.5186 - accuracy: 0.3277\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.2854 - accuracy: 0.4210\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.2469 - accuracy: 0.9254\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.2326 - accuracy: 0.9254\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.2217 - accuracy: 0.9082\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.1980 - accuracy: 0.8822\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2212 - accuracy: 0.8553\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 2s 30ms/step - loss: 0.4991 - accuracy: 0.5428\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.2870 - accuracy: 0.1835\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.2605 - accuracy: 0.8522\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.2461 - accuracy: 0.7802\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.2292 - accuracy: 0.8766\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.2035 - accuracy: 0.8390\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2067 - accuracy: 0.8638\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 2s 22ms/step - loss: 0.5064 - accuracy: 0.8473\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.2797 - accuracy: 0.4691\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.2438 - accuracy: 0.7494\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.2262 - accuracy: 0.9210\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.2169 - accuracy: 0.9210\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.1983 - accuracy: 0.7762\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2518 - accuracy: 0.9069\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 1s 6ms/step - loss: 0.5349 - accuracy: 0.6988\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3281 - accuracy: 0.8557\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2477 - accuracy: 0.5177\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2151 - accuracy: 0.6960\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1883 - accuracy: 0.7821\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1744 - accuracy: 0.7134\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1794 - accuracy: 0.7979\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 1s 8ms/step - loss: 0.5298 - accuracy: 0.5147\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3236 - accuracy: 0.5489\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2502 - accuracy: 0.3580\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2085 - accuracy: 0.5713\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1795 - accuracy: 0.5796\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1655 - accuracy: 0.4951\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.2050 - accuracy: 0.5785\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 1s 5ms/step - loss: 0.4716 - accuracy: 0.8691\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2660 - accuracy: 0.4983\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2182 - accuracy: 0.3172\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1893 - accuracy: 0.4530\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1662 - accuracy: 0.4787\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1520 - accuracy: 0.5597\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2249 - accuracy: 0.3960\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 5s 332ms/step - loss: 0.3798 - accuracy: 0.6904\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 4s 348ms/step - loss: 0.2361 - accuracy: 0.9205\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 4s 351ms/step - loss: 0.2079 - accuracy: 0.8772\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 0.1875 - accuracy: 0.8897\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 4s 357ms/step - loss: 0.1746 - accuracy: 0.8912\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.1919 - accuracy: 0.8897\n",
      "6/6 [==============================] - 1s 84ms/step - loss: 0.2338 - accuracy: 0.8814\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 5s 335ms/step - loss: 0.4442 - accuracy: 0.3523\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 4s 338ms/step - loss: 0.2757 - accuracy: 0.5296\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 4s 332ms/step - loss: 0.2321 - accuracy: 0.8484\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 4s 333ms/step - loss: 0.2006 - accuracy: 0.8643\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 4s 332ms/step - loss: 0.1851 - accuracy: 0.8758\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 4s 357ms/step - loss: 0.1685 - accuracy: 0.6992\n",
      "6/6 [==============================] - 1s 77ms/step - loss: 0.1990 - accuracy: 0.9145\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 5s 326ms/step - loss: 0.4342 - accuracy: 0.4279\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 4s 328ms/step - loss: 0.2457 - accuracy: 0.7341\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 4s 325ms/step - loss: 0.2137 - accuracy: 0.9089\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 4s 332ms/step - loss: 0.1891 - accuracy: 0.8564\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 4s 327ms/step - loss: 0.1764 - accuracy: 0.8574\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 4s 325ms/step - loss: 0.1504 - accuracy: 0.7507\n",
      "6/6 [==============================] - 1s 80ms/step - loss: 0.2386 - accuracy: 0.8234\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 2s 33ms/step - loss: 0.4520 - accuracy: 0.6040\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.2695 - accuracy: 0.8537\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.2436 - accuracy: 0.9254\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.2242 - accuracy: 0.9235\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.2002 - accuracy: 0.8941\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.1782 - accuracy: 0.8956\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2026 - accuracy: 0.8695\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 1s 23ms/step - loss: 0.4731 - accuracy: 0.5814\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.2850 - accuracy: 0.2372\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.2508 - accuracy: 0.8645\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.2144 - accuracy: 0.8257\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1955 - accuracy: 0.8569\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1794 - accuracy: 0.8464\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1904 - accuracy: 0.4490\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 1s 20ms/step - loss: 0.4803 - accuracy: 0.6092\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.2710 - accuracy: 0.2273\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.2408 - accuracy: 0.6109\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.2204 - accuracy: 0.5589\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1993 - accuracy: 0.6914\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1842 - accuracy: 0.7467\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2462 - accuracy: 0.8930\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 2s 9ms/step - loss: 0.6768 - accuracy: 0.5335\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5193 - accuracy: 0.9254\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3515 - accuracy: 0.9254\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2791 - accuracy: 0.9254\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2591 - accuracy: 0.9254\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2467 - accuracy: 0.9254\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2628 - accuracy: 0.8980\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 2s 9ms/step - loss: 0.6787 - accuracy: 0.0813\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5393 - accuracy: 0.0813\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3521 - accuracy: 0.2248\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2933 - accuracy: 0.6468\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2728 - accuracy: 0.1100\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2604 - accuracy: 0.7479\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2217 - accuracy: 0.5417\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 2s 10ms/step - loss: 0.6825 - accuracy: 0.0595\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5852 - accuracy: 0.0595\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3512 - accuracy: 0.2649\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2726 - accuracy: 0.9210\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2482 - accuracy: 0.1955\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2358 - accuracy: 0.6820\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2780 - accuracy: 0.9069\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 4s 236ms/step - loss: 0.3876 - accuracy: 0.6370\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 3s 243ms/step - loss: 0.2408 - accuracy: 0.7980\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 3s 241ms/step - loss: 0.2036 - accuracy: 0.8998\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 3s 243ms/step - loss: 0.1792 - accuracy: 0.9036\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 3s 245ms/step - loss: 0.1648 - accuracy: 0.8955\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 3s 244ms/step - loss: 0.1493 - accuracy: 0.8955\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.1746 - accuracy: 0.8933\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 4s 228ms/step - loss: 0.4324 - accuracy: 0.4242\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 3s 240ms/step - loss: 0.2714 - accuracy: 0.5115\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 3s 243ms/step - loss: 0.2173 - accuracy: 0.7684\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 3s 258ms/step - loss: 0.1774 - accuracy: 0.8781\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 3s 256ms/step - loss: 0.1668 - accuracy: 0.7964\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 3s 252ms/step - loss: 0.1524 - accuracy: 0.7277\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.2201 - accuracy: 0.9284\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 4s 238ms/step - loss: 0.4141 - accuracy: 0.6811\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 3s 240ms/step - loss: 0.2415 - accuracy: 0.4588\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 0.2083 - accuracy: 0.5523\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 3s 239ms/step - loss: 0.1807 - accuracy: 0.4298\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 3s 243ms/step - loss: 0.1545 - accuracy: 0.5723\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 3s 240ms/step - loss: 0.1349 - accuracy: 0.5639\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.2122 - accuracy: 0.8960\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 2s 33ms/step - loss: 0.5544 - accuracy: 0.0533\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.3107 - accuracy: 0.8511\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.2599 - accuracy: 0.6208\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.2445 - accuracy: 0.9254\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.2324 - accuracy: 0.9254\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.2217 - accuracy: 0.9254\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2440 - accuracy: 0.8980\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 2s 32ms/step - loss: 0.5741 - accuracy: 0.1315\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.3368 - accuracy: 0.5660\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.2764 - accuracy: 0.1880\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.2587 - accuracy: 0.9024\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.2487 - accuracy: 0.9024\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.2355 - accuracy: 0.9024\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2129 - accuracy: 0.9440\n",
      "Epoch 1/6\n",
      "12/12 [==============================] - 3s 44ms/step - loss: 0.5547 - accuracy: 0.8478\n",
      "Epoch 2/6\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.3110 - accuracy: 0.4484\n",
      "Epoch 3/6\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.2566 - accuracy: 0.4706\n",
      "Epoch 4/6\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.2373 - accuracy: 0.6003\n",
      "Epoch 5/6\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.2269 - accuracy: 0.7563\n",
      "Epoch 6/6\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.2165 - accuracy: 0.9210\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2756 - accuracy: 0.9069\n",
      "Epoch 1/6\n",
      "18/18 [==============================] - 3s 39ms/step - loss: 0.5110 - accuracy: 0.3527\n",
      "Epoch 2/6\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.2849 - accuracy: 0.4996\n",
      "Epoch 3/6\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2514 - accuracy: 0.7093\n",
      "Epoch 4/6\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.2359 - accuracy: 0.9163\n",
      "Epoch 5/6\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.2185 - accuracy: 0.8952\n",
      "Epoch 6/6\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 0.1909 - accuracy: 0.8744\n",
      "0.916291356086731 {'nn': 128, 'nl': 19}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "model = KerasClassifier(build_fn=creat_model, epochs=6, batch_size=512)\n",
    "nn_nl_params = {'nl': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'nn': [32, 64, 128, 256, 512, 1024, 2048]}\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=nn_nl_params, cv=3)\n",
    "random_search_results = random_search.fit(X, y)\n",
    "\n",
    "print(random_search_results.best_score_, random_search_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22dde845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to determine the best optimizer, the proper numbers of epochs , the batch_size and activation methods\n",
    "# so we repeat all previous steps again\n",
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "def Create_model (optimizer = 'adam', activation = 'relu', batch_size = 256):\n",
    "    model = Sequential ()\n",
    "    model.add (Dense (1024, input_shape = (32,), activation = activation))\n",
    "    for i in range (0,9):\n",
    "        model.add (Dense (1024, activation = activation))\n",
    "    model.add (Dense (4, activation = 'sigmoid'))\n",
    "    model.compile (optimizer=optimizer, loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "574dd9bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_11080\\2935539184.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=Create_model, epochs=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 2s 102ms/step - loss: 0.6884 - accuracy: 0.0320\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.6770 - accuracy: 0.0905\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.6661 - accuracy: 0.2599\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.6554 - accuracy: 0.4013\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.6450 - accuracy: 0.5401\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.6345 - accuracy: 0.6629\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.6240 - accuracy: 0.7482\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.6135 - accuracy: 0.8062\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.6030 - accuracy: 0.8390\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.5924 - accuracy: 0.8628\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.5926 - accuracy: 0.8423\n",
      "Epoch 1/10\n",
      "12/12 [==============================] - 2s 102ms/step - loss: 0.6898 - accuracy: 0.4260\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 1s 99ms/step - loss: 0.6797 - accuracy: 0.3841\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 1s 100ms/step - loss: 0.6702 - accuracy: 0.3084\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 1s 99ms/step - loss: 0.6610 - accuracy: 0.2730\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.6521 - accuracy: 0.2351\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.6432 - accuracy: 0.2140\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.6343 - accuracy: 0.1966\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.6253 - accuracy: 0.1776\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.6163 - accuracy: 0.1738\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 1s 101ms/step - loss: 0.6072 - accuracy: 0.1714\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.5933 - accuracy: 0.1902\n",
      "Epoch 1/10\n",
      "12/12 [==============================] - 2s 97ms/step - loss: 0.6872 - accuracy: 0.9107\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 1s 98ms/step - loss: 0.6764 - accuracy: 0.9207\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 1s 98ms/step - loss: 0.6660 - accuracy: 0.9210\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 1s 98ms/step - loss: 0.6560 - accuracy: 0.9210\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 1s 99ms/step - loss: 0.6461 - accuracy: 0.9210\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 1s 99ms/step - loss: 0.6362 - accuracy: 0.9210\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 1s 99ms/step - loss: 0.6263 - accuracy: 0.9210\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.6163 - accuracy: 0.9210\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.6061 - accuracy: 0.9210\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.5956 - accuracy: 0.9210\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.5963 - accuracy: 0.9069\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 2s 158ms/step - loss: 0.6654 - accuracy: 0.2805\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 1s 161ms/step - loss: 0.6056 - accuracy: 0.2376\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 1s 166ms/step - loss: 0.5530 - accuracy: 0.2772\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 1s 163ms/step - loss: 0.5045 - accuracy: 0.3360\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 1s 162ms/step - loss: 0.4590 - accuracy: 0.3840\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 1s 165ms/step - loss: 0.4167 - accuracy: 0.4213\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 1s 169ms/step - loss: 0.3785 - accuracy: 0.4491\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 1s 170ms/step - loss: 0.3451 - accuracy: 0.4775\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 1s 159ms/step - loss: 0.3172 - accuracy: 0.5071\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 1s 161ms/step - loss: 0.2946 - accuracy: 0.5350\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.3001 - accuracy: 0.4422\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 2s 155ms/step - loss: 0.6704 - accuracy: 0.2819\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 1s 159ms/step - loss: 0.6052 - accuracy: 0.2808\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 1s 166ms/step - loss: 0.5489 - accuracy: 0.2924\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 1s 170ms/step - loss: 0.4982 - accuracy: 0.3003\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 1s 166ms/step - loss: 0.4527 - accuracy: 0.3109\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 1s 165ms/step - loss: 0.4125 - accuracy: 0.3303\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 1s 167ms/step - loss: 0.3777 - accuracy: 0.3487\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 1s 173ms/step - loss: 0.3483 - accuracy: 0.3626\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 1s 172ms/step - loss: 0.3238 - accuracy: 0.3763\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 1s 171ms/step - loss: 0.3037 - accuracy: 0.3939\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.3278 - accuracy: 0.3641\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 2s 157ms/step - loss: 0.6735 - accuracy: 0.2341\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 1s 166ms/step - loss: 0.6062 - accuracy: 0.2841\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 1s 175ms/step - loss: 0.5525 - accuracy: 0.3098\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 1s 163ms/step - loss: 0.5063 - accuracy: 0.3291\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 1s 163ms/step - loss: 0.4652 - accuracy: 0.3379\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 1s 162ms/step - loss: 0.4282 - accuracy: 0.3440\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 1s 172ms/step - loss: 0.3945 - accuracy: 0.3500\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 1s 162ms/step - loss: 0.3639 - accuracy: 0.3551\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 1s 164ms/step - loss: 0.3362 - accuracy: 0.3593\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 1s 161ms/step - loss: 0.3115 - accuracy: 0.3676\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.3352 - accuracy: 0.4705\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 150ms/step - loss: 0.6913 - accuracy: 0.0389\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 0.6853 - accuracy: 0.2599\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 0.6795 - accuracy: 0.5333\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 0.6740 - accuracy: 0.6998\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 0.6686 - accuracy: 0.7941\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 1s 159ms/step - loss: 0.6633 - accuracy: 0.8482\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 1s 161ms/step - loss: 0.6580 - accuracy: 0.8759\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 1s 160ms/step - loss: 0.6528 - accuracy: 0.8948\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 1s 161ms/step - loss: 0.6476 - accuracy: 0.9024\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 1s 166ms/step - loss: 0.6424 - accuracy: 0.9097\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x000001E77647D8A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6420 - accuracy: 0.8841\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 2s 151ms/step - loss: 0.6916 - accuracy: 0.8927\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 0.6865 - accuracy: 0.9018\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 0.6816 - accuracy: 0.9023\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 1s 156ms/step - loss: 0.6769 - accuracy: 0.9024\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 1s 156ms/step - loss: 0.6722 - accuracy: 0.9024\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 1s 158ms/step - loss: 0.6676 - accuracy: 0.9024\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 1s 157ms/step - loss: 0.6631 - accuracy: 0.9024\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 1s 156ms/step - loss: 0.6586 - accuracy: 0.9024\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 0.6542 - accuracy: 0.9024\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 1s 162ms/step - loss: 0.6498 - accuracy: 0.9024\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001E77DACD800> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6433 - accuracy: 0.9440\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 2s 152ms/step - loss: 0.6857 - accuracy: 0.4847\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 0.6800 - accuracy: 0.7297\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 0.6743 - accuracy: 0.8516\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 0.6688 - accuracy: 0.8993\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 0.6633 - accuracy: 0.9165\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 0.6578 - accuracy: 0.9200\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 0.6524 - accuracy: 0.9207\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 0.6469 - accuracy: 0.9207\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 1s 156ms/step - loss: 0.6415 - accuracy: 0.9210\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 1s 156ms/step - loss: 0.6360 - accuracy: 0.9210\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6377 - accuracy: 0.9069\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 5s 139ms/step - loss: 0.4113 - accuracy: 0.7397\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 4s 163ms/step - loss: 0.3417 - accuracy: 0.6652\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 4s 178ms/step - loss: 0.3397 - accuracy: 0.8136\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 4s 179ms/step - loss: 0.3388 - accuracy: 0.8888\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 4s 182ms/step - loss: 0.3393 - accuracy: 0.7825\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 4s 179ms/step - loss: 0.3393 - accuracy: 0.9037\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 4s 177ms/step - loss: 0.3388 - accuracy: 0.9254\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 4s 178ms/step - loss: 0.3394 - accuracy: 0.9254\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 4s 177ms/step - loss: 0.3383 - accuracy: 0.8872\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 4s 178ms/step - loss: 0.3388 - accuracy: 0.9254\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.3956 - accuracy: 0.8980\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 5s 144ms/step - loss: 0.4328 - accuracy: 0.4868\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 4s 150ms/step - loss: 0.3717 - accuracy: 0.7269\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 4s 148ms/step - loss: 0.3698 - accuracy: 0.6892\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 3s 145ms/step - loss: 0.3704 - accuracy: 0.5894\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 3s 145ms/step - loss: 0.3701 - accuracy: 0.5779\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 3s 144ms/step - loss: 0.3698 - accuracy: 0.8329\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 3s 144ms/step - loss: 0.3706 - accuracy: 0.5909\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 3s 145ms/step - loss: 0.3710 - accuracy: 0.5208\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 3s 145ms/step - loss: 0.3711 - accuracy: 0.5528\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 3s 144ms/step - loss: 0.3713 - accuracy: 0.5349\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.3226 - accuracy: 0.9440\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 4s 129ms/step - loss: 0.4054 - accuracy: 0.6180\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 3s 138ms/step - loss: 0.3551 - accuracy: 0.9210\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 3s 137ms/step - loss: 0.3519 - accuracy: 0.9210\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 3s 141ms/step - loss: 0.3509 - accuracy: 0.9210\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 3s 140ms/step - loss: 0.3508 - accuracy: 0.9210\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 3s 140ms/step - loss: 0.3511 - accuracy: 0.8461\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 3s 146ms/step - loss: 0.3520 - accuracy: 0.8836\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 3s 142ms/step - loss: 0.3513 - accuracy: 0.9210\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 3s 139ms/step - loss: 0.3514 - accuracy: 0.8491\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 3s 142ms/step - loss: 0.3516 - accuracy: 0.8464\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.3592 - accuracy: 0.9069\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 2s 283ms/step - loss: 0.5667 - accuracy: 0.0573\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 289ms/step - loss: 0.4317 - accuracy: 0.0573\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 289ms/step - loss: 0.3845 - accuracy: 0.0573\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 292ms/step - loss: 0.3640 - accuracy: 0.6332\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 284ms/step - loss: 0.3536 - accuracy: 0.9254\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 288ms/step - loss: 0.3479 - accuracy: 0.9254\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 286ms/step - loss: 0.3445 - accuracy: 0.9254\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 274ms/step - loss: 0.3423 - accuracy: 0.9254\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 283ms/step - loss: 0.3409 - accuracy: 0.9254\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 283ms/step - loss: 0.3399 - accuracy: 0.9254\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3847 - accuracy: 0.8980\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 288ms/step - loss: 0.7085 - accuracy: 0.0101\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 278ms/step - loss: 0.4949 - accuracy: 0.0333\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 294ms/step - loss: 0.4271 - accuracy: 0.0813\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 286ms/step - loss: 0.4005 - accuracy: 0.0813\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 280ms/step - loss: 0.3878 - accuracy: 0.0813\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 272ms/step - loss: 0.3811 - accuracy: 0.9024\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 270ms/step - loss: 0.3772 - accuracy: 0.9024\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 270ms/step - loss: 0.3747 - accuracy: 0.9024\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.3731 - accuracy: 0.9024\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 297ms/step - loss: 0.3720 - accuracy: 0.9024\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3257 - accuracy: 0.9440\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 2s 275ms/step - loss: 0.4998 - accuracy: 0.0096\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 280ms/step - loss: 0.4139 - accuracy: 0.0096\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 277ms/step - loss: 0.3828 - accuracy: 0.9210\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 281ms/step - loss: 0.3691 - accuracy: 0.9210\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 276ms/step - loss: 0.3620 - accuracy: 0.9210\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 275ms/step - loss: 0.3580 - accuracy: 0.9210\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 277ms/step - loss: 0.3556 - accuracy: 0.9210\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 280ms/step - loss: 0.3540 - accuracy: 0.9210\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 278ms/step - loss: 0.3530 - accuracy: 0.9210\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 279ms/step - loss: 0.3522 - accuracy: 0.9210\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3596 - accuracy: 0.9069\n",
      "Epoch 1/10\n",
      "12/12 [==============================] - 3s 133ms/step - loss: 1.1789 - accuracy: 0.3101\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 0.4013 - accuracy: 0.4347\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 2s 136ms/step - loss: 0.3226 - accuracy: 0.4652\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 0.2863 - accuracy: 0.5096\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 0.2540 - accuracy: 0.4372\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 0.2271 - accuracy: 0.6807\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 2s 137ms/step - loss: 0.1984 - accuracy: 0.7480\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 0.1855 - accuracy: 0.7386\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 0.1880 - accuracy: 0.6900\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 0.1806 - accuracy: 0.6859\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.1853 - accuracy: 0.6171\n",
      "Epoch 1/10\n",
      "12/12 [==============================] - 3s 131ms/step - loss: 1.0646 - accuracy: 0.2496\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 0.4749 - accuracy: 0.3470\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 2s 137ms/step - loss: 0.4364 - accuracy: 0.3180\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 2s 136ms/step - loss: 0.3976 - accuracy: 0.4236\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 0.3245 - accuracy: 0.6596\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 2s 136ms/step - loss: 0.2541 - accuracy: 0.7842\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 0.2226 - accuracy: 0.8002\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 2s 136ms/step - loss: 0.2001 - accuracy: 0.7156\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 0.1921 - accuracy: 0.7852\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 0.1791 - accuracy: 0.8088\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.2313 - accuracy: 0.8135\n",
      "Epoch 1/10\n",
      "12/12 [==============================] - 3s 132ms/step - loss: 1.1051 - accuracy: 0.2619\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 2s 131ms/step - loss: 0.4939 - accuracy: 0.1511\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 0.4656 - accuracy: 0.1698\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 0.4642 - accuracy: 0.1304\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 0.4375 - accuracy: 0.1272\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 0.4239 - accuracy: 0.1784\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 0.3975 - accuracy: 0.3016\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 2s 135ms/step - loss: 0.3985 - accuracy: 0.3341\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 0.3142 - accuracy: 0.2900\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 0.4643 - accuracy: 0.7096\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.3901 - accuracy: 0.8390\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 4s 103ms/step - loss: 0.6829 - accuracy: 0.4838\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 3s 138ms/step - loss: 0.6607 - accuracy: 0.9041\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 3s 143ms/step - loss: 0.6393 - accuracy: 0.9251\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 4s 146ms/step - loss: 0.6178 - accuracy: 0.9254\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 3s 144ms/step - loss: 0.5959 - accuracy: 0.9254\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 3s 144ms/step - loss: 0.5733 - accuracy: 0.9254\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 4s 148ms/step - loss: 0.5496 - accuracy: 0.9254\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 3s 145ms/step - loss: 0.5247 - accuracy: 0.9254\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 3s 144ms/step - loss: 0.4986 - accuracy: 0.9254\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 3s 143ms/step - loss: 0.4719 - accuracy: 0.9254\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.4761 - accuracy: 0.8980\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 3s 118ms/step - loss: 0.6825 - accuracy: 0.8837\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 3s 128ms/step - loss: 0.6624 - accuracy: 0.8380\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 3s 136ms/step - loss: 0.6430 - accuracy: 0.7822\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 3s 130ms/step - loss: 0.6237 - accuracy: 0.8178\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 3s 129ms/step - loss: 0.6041 - accuracy: 0.8312\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 3s 132ms/step - loss: 0.5842 - accuracy: 0.8885\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 3s 128ms/step - loss: 0.5637 - accuracy: 0.8966\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 3s 127ms/step - loss: 0.5426 - accuracy: 0.9014\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 3s 127ms/step - loss: 0.5209 - accuracy: 0.9024\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 3s 134ms/step - loss: 0.4989 - accuracy: 0.9023\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.4619 - accuracy: 0.9440\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 3s 106ms/step - loss: 0.6840 - accuracy: 0.4603\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 3s 114ms/step - loss: 0.6625 - accuracy: 0.8335\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 3s 118ms/step - loss: 0.6423 - accuracy: 0.9028\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 3s 115ms/step - loss: 0.6223 - accuracy: 0.9177\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 3s 119ms/step - loss: 0.6021 - accuracy: 0.9197\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 3s 116ms/step - loss: 0.5814 - accuracy: 0.9207\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 3s 115ms/step - loss: 0.5599 - accuracy: 0.9210\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 3s 114ms/step - loss: 0.5373 - accuracy: 0.9210\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 3s 113ms/step - loss: 0.5134 - accuracy: 0.9210\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 3s 112ms/step - loss: 0.4883 - accuracy: 0.9210\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.4884 - accuracy: 0.9069\n",
      "Epoch 1/10\n",
      "12/12 [==============================] - 3s 151ms/step - loss: 0.4488 - accuracy: 0.7753\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 2s 161ms/step - loss: 0.3778 - accuracy: 0.7732\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 2s 165ms/step - loss: 0.3413 - accuracy: 0.9254\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 2s 163ms/step - loss: 0.3395 - accuracy: 0.9254\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 2s 164ms/step - loss: 0.3382 - accuracy: 0.9254\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 2s 166ms/step - loss: 0.3378 - accuracy: 0.9254\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 2s 164ms/step - loss: 0.3379 - accuracy: 0.9254\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 2s 163ms/step - loss: 0.3384 - accuracy: 0.9254\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 2s 161ms/step - loss: 0.3385 - accuracy: 0.8530\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 2s 161ms/step - loss: 0.3379 - accuracy: 0.9254\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.3819 - accuracy: 0.8980\n",
      "Epoch 1/10\n",
      "12/12 [==============================] - 3s 138ms/step - loss: 0.4453 - accuracy: 0.4118\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 0.3905 - accuracy: 0.6251\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 0.3738 - accuracy: 0.6263\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 2s 135ms/step - loss: 0.3728 - accuracy: 0.5594\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 2s 136ms/step - loss: 0.3701 - accuracy: 0.6245\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.3694 - accuracy: 0.6273\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 2s 140ms/step - loss: 0.3698 - accuracy: 0.9024\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 0.3696 - accuracy: 0.5011\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 2s 151ms/step - loss: 0.3699 - accuracy: 0.5546\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 0.3697 - accuracy: 0.9024\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.3192 - accuracy: 0.9440\n",
      "Epoch 1/10\n",
      "12/12 [==============================] - 3s 133ms/step - loss: 0.4824 - accuracy: 0.5731\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 2s 136ms/step - loss: 0.3936 - accuracy: 0.7875\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 2s 137ms/step - loss: 0.3570 - accuracy: 0.7752\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 2s 140ms/step - loss: 0.3521 - accuracy: 0.9210\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 0.3511 - accuracy: 0.9210\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 0.3507 - accuracy: 0.9210\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 2s 137ms/step - loss: 0.3508 - accuracy: 0.9210\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 0.3505 - accuracy: 0.9210\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 0.3506 - accuracy: 0.9210\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 2s 140ms/step - loss: 0.3509 - accuracy: 0.9210\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.3589 - accuracy: 0.9069\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 6s 88ms/step - loss: 0.3292 - accuracy: 0.8880\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 4s 87ms/step - loss: 0.2077 - accuracy: 0.8888\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 4s 88ms/step - loss: 0.1854 - accuracy: 0.8617\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 4s 87ms/step - loss: 0.1842 - accuracy: 0.8965\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 4s 87ms/step - loss: 0.1702 - accuracy: 0.8943\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 4s 89ms/step - loss: 0.1616 - accuracy: 0.8535\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 4s 85ms/step - loss: 0.1584 - accuracy: 0.8912\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 4s 88ms/step - loss: 0.1541 - accuracy: 0.8887\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 4s 91ms/step - loss: 0.1483 - accuracy: 0.8577\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 4s 90ms/step - loss: 0.1485 - accuracy: 0.8913\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.1756 - accuracy: 0.3928\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 5s 85ms/step - loss: 0.3244 - accuracy: 0.5711\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 4s 87ms/step - loss: 0.2267 - accuracy: 0.7804\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 4s 88ms/step - loss: 0.1945 - accuracy: 0.8355\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 4s 87ms/step - loss: 0.1808 - accuracy: 0.8411\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 4s 88ms/step - loss: 0.1723 - accuracy: 0.7870\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 4s 87ms/step - loss: 0.1631 - accuracy: 0.7871\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 4s 88ms/step - loss: 0.1584 - accuracy: 0.8872\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 4s 87ms/step - loss: 0.1570 - accuracy: 0.8261\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 4s 89ms/step - loss: 0.1487 - accuracy: 0.8252\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 4s 87ms/step - loss: 0.1417 - accuracy: 0.8259\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 0.2113 - accuracy: 0.6425\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 5s 81ms/step - loss: 0.3167 - accuracy: 0.7161\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 4s 84ms/step - loss: 0.2026 - accuracy: 0.7951\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 4s 85ms/step - loss: 0.1792 - accuracy: 0.5852\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 4s 85ms/step - loss: 0.1583 - accuracy: 0.6894\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 4s 85ms/step - loss: 0.1524 - accuracy: 0.8690\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 4s 85ms/step - loss: 0.1384 - accuracy: 0.6639\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 4s 85ms/step - loss: 0.1437 - accuracy: 0.6568\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 4s 85ms/step - loss: 0.1273 - accuracy: 0.6478\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 4s 90ms/step - loss: 0.1234 - accuracy: 0.7691\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 4s 87ms/step - loss: 0.1228 - accuracy: 0.6521\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 0.2056 - accuracy: 0.8817\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 4s 72ms/step - loss: 0.5010 - accuracy: 0.3713\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 5s 95ms/step - loss: 0.2706 - accuracy: 0.5471\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 5s 97ms/step - loss: 0.2225 - accuracy: 0.6897\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 5s 98ms/step - loss: 0.2090 - accuracy: 0.7460\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 5s 97ms/step - loss: 0.2011 - accuracy: 0.7459\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 5s 94ms/step - loss: 0.1952 - accuracy: 0.7646\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 5s 97ms/step - loss: 0.1903 - accuracy: 0.7591\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 5s 96ms/step - loss: 0.1866 - accuracy: 0.7598\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 5s 95ms/step - loss: 0.1831 - accuracy: 0.7654\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 5s 100ms/step - loss: 0.1801 - accuracy: 0.7621\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.1669 - accuracy: 0.6108\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 5s 87ms/step - loss: 0.4835 - accuracy: 0.3595\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 4s 91ms/step - loss: 0.2719 - accuracy: 0.4756\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 4s 93ms/step - loss: 0.2246 - accuracy: 0.5436\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 5s 94ms/step - loss: 0.2077 - accuracy: 0.5875\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 4s 91ms/step - loss: 0.1970 - accuracy: 0.5935\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 4s 90ms/step - loss: 0.1897 - accuracy: 0.5958\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 4s 93ms/step - loss: 0.1839 - accuracy: 0.6068\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 4s 92ms/step - loss: 0.1792 - accuracy: 0.6013\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 4s 92ms/step - loss: 0.1753 - accuracy: 0.6112\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 5s 97ms/step - loss: 0.1722 - accuracy: 0.5996\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.1941 - accuracy: 0.5716\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 4s 81ms/step - loss: 0.4922 - accuracy: 0.3727\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 4s 84ms/step - loss: 0.2646 - accuracy: 0.4405\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 4s 84ms/step - loss: 0.2081 - accuracy: 0.4945\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 4s 88ms/step - loss: 0.1928 - accuracy: 0.5022\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 4s 85ms/step - loss: 0.1845 - accuracy: 0.4938\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 4s 86ms/step - loss: 0.1785 - accuracy: 0.4892\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 4s 85ms/step - loss: 0.1734 - accuracy: 0.4885\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 4s 82ms/step - loss: 0.1691 - accuracy: 0.4896\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 4s 81ms/step - loss: 0.1656 - accuracy: 0.4968\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 4s 84ms/step - loss: 0.1622 - accuracy: 0.4845\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.2236 - accuracy: 0.7203\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 6s 146ms/step - loss: 0.4081 - accuracy: 0.6763\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 5s 151ms/step - loss: 0.3549 - accuracy: 0.8606\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 5s 151ms/step - loss: 0.3538 - accuracy: 0.8457\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 5s 152ms/step - loss: 0.3531 - accuracy: 0.8189\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 5s 152ms/step - loss: 0.3546 - accuracy: 0.6567\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 6s 153ms/step - loss: 0.3535 - accuracy: 0.7992\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 5s 152ms/step - loss: 0.3533 - accuracy: 0.8426\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 5s 151ms/step - loss: 0.3537 - accuracy: 0.8680\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 6s 158ms/step - loss: 0.3537 - accuracy: 0.8596\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 6s 155ms/step - loss: 0.3536 - accuracy: 0.7940\n",
      "0.916291356086731 {'optimizer': 'adam', 'batch_size': 256, 'activation': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model = KerasClassifier(build_fn=Create_model, epochs=10)\n",
    "\n",
    "other_params = {\n",
    "    'optimizer': ['sgd','adam'],\n",
    "    'activation': ['relu', 'tanh', 'sigmoid'],\n",
    "    'batch_size': [128, 256, 512, 1024, 2048]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=other_params, cv=3)\n",
    "random_search_results = random_search.fit(X, y)\n",
    "\n",
    "print(random_search_results.best_score_, random_search_results.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9179172",
   "metadata": {},
   "source": [
    "## 3) Final design of neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3446e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e70091d490>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Neural network anatomy\n",
    "\n",
    "final_model = Sequential()\n",
    "final_model.add (Dense (256,input_shape = (32,), activation = 'relu'))\n",
    "\n",
    "for i in range (0,19):\n",
    "    final_model.add (Dense(128, activation = 'relu'))\n",
    "\n",
    "final_model.add (Dense (4, activation = 'sigmoid'))\n",
    "\n",
    "# model compile\n",
    "final_model.compile (optimizer='adam', loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "# model training\n",
    "final_model.fit (x_train, y_train, epochs = 1000, validation_data = (x_test,y_test), verbose = 0, batch_size = 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "31bc3f36",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [134]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mfinal_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(final_model\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(final_model.history.history['accuracy'])\n",
    "plt.plot(final_model.history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5234099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step\n",
      "Confusion matrix for Label 0:\n",
      "[[1329  104]\n",
      " [ 130  248]]\n",
      "\n",
      "\n",
      "Confusion matrix for Label 1:\n",
      "[[1481    7]\n",
      " [  39  284]]\n",
      "\n",
      "\n",
      "Confusion matrix for Label 2:\n",
      "[[1710   28]\n",
      " [  46   27]]\n",
      "\n",
      "\n",
      "Confusion matrix for Label 3:\n",
      "[[1558   85]\n",
      " [ 113   55]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming you have your test data and labels stored in variables x_test and y_test\n",
    "# You can get the predicted labels from your trained model using predict() method\n",
    "y_pred = final_model.predict(x_test)\n",
    "y_pred_binary = np.round(y_pred)  # Convert probabilities to binary values\n",
    "\n",
    "# Calculate the confusion matrix for each label\n",
    "num_labels = y_test.shape[1]\n",
    "confusion_matrices = []\n",
    "for label in range(num_labels):\n",
    "    label_confusion_matrix = confusion_matrix(y_test[:, label], y_pred_binary[:, label])\n",
    "    confusion_matrices.append(label_confusion_matrix)\n",
    "\n",
    "# Print confusion matrix for each label\n",
    "for label, matrix in enumerate(confusion_matrices):\n",
    "    print(f\"Confusion matrix for Label {label}:\")\n",
    "    print(matrix)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "637b68e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = final_model.predict(x_test)\n",
    "y_pred_binary = np.round(y_pred)  # Convert probabilities to binary values\n",
    "\n",
    "# Calculate the confusion matrix for each label\n",
    "num_labels = y_test.shape[1]\n",
    "confusion_matrices = []\n",
    "for label in range(num_labels):\n",
    "    label_confusion_matrix = confusion_matrix(y_test[:, label], y_pred_binary[:, label])\n",
    "    confusion_matrices.append(label_confusion_matrix)\n",
    "\n",
    "# Plot confusion matrix tables for each label\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "for label, matrix in enumerate(confusion_matrices):\n",
    "    row = label // 2\n",
    "    col = label % 2\n",
    "    ax = axes[row, col]\n",
    "    ax.imshow(matrix, cmap='Blues')\n",
    "\n",
    "    # Add labels to the table\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(matrix.shape[1]):\n",
    "            ax.text(j, i, str(matrix[i, j]), ha='center', va='center', color='white' if matrix[i, j] > matrix.max() / 2 else 'black')\n",
    "\n",
    "    ax.set_title(f\"Confusion matrix for Label {label}\")\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99abb290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step\n",
      "Metrics for Outcome 0:\n",
      "Precision: 0.7045454545454546\n",
      "Recall: 0.656084656084656\n",
      "F1-score: 0.6794520547945205\n",
      "\n",
      "\n",
      "Metrics for Outcome 1:\n",
      "Precision: 0.9759450171821306\n",
      "Recall: 0.8792569659442725\n",
      "F1-score: 0.9250814332247557\n",
      "\n",
      "\n",
      "Metrics for Outcome 2:\n",
      "Precision: 0.4909090909090909\n",
      "Recall: 0.3698630136986301\n",
      "F1-score: 0.421875\n",
      "\n",
      "\n",
      "Metrics for Outcome 3:\n",
      "Precision: 0.39285714285714285\n",
      "Recall: 0.3273809523809524\n",
      "F1-score: 0.35714285714285715\n",
      "\n",
      "\n",
      "Metrics for micro avg:\n",
      "Precision: 0.7326968973747017\n",
      "Recall: 0.6518046709129511\n",
      "F1-score: 0.6898876404494383\n",
      "\n",
      "\n",
      "Metrics for macro avg:\n",
      "Precision: 0.6410641763734547\n",
      "Recall: 0.5581463970271278\n",
      "F1-score: 0.5958878362905333\n",
      "\n",
      "\n",
      "Metrics for weighted avg:\n",
      "Precision: 0.7254615562679126\n",
      "Recall: 0.6518046709129511\n",
      "F1-score: 0.686232542084846\n",
      "\n",
      "\n",
      "Metrics for samples avg:\n",
      "Precision: 0.20499723909442297\n",
      "Recall: 0.19823302043070126\n",
      "F1-score: 0.1925245194709579\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming you have your test data and labels stored in variables x_test and y_test\n",
    "# You can get the predicted labels from your trained model using predict() method\n",
    "y_pred = final_model.predict(x_test)\n",
    "y_pred_binary = np.round(y_pred)  # Convert probabilities to binary values\n",
    "\n",
    "# Calculate the classification report for all outcomes\n",
    "classification_result = classification_report(y_test, y_pred_binary, target_names=['Outcome 0', 'Outcome 1', 'Outcome 2', 'Outcome 3'], output_dict=True)\n",
    "\n",
    "# Print the classification report\n",
    "for outcome, metrics in classification_result.items():\n",
    "    print(f\"Metrics for {outcome}:\")\n",
    "    print(f\"Precision: {metrics['precision']}\")\n",
    "    print(f\"Recall: {metrics['recall']}\")\n",
    "    print(f\"F1-score: {metrics['f1-score']}\")\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
